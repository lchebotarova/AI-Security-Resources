| Resource                                                                                      | Topic          | Category         | Link                                                                                                                                     |
|:----------------------------------------------------------------------------------------------|:---------------|:-----------------|:-----------------------------------------------------------------------------------------------------------------------------------------|
| BlueDot Impact: AI Safety and AI Governance                                                   | Safety         | Course           | https://aisafetyfundamentals.com/                                                                                                        |
| The Alan Turing Institute: Introduction to Transparent Machine Learning                       | Transparency   | Course           | https://www.turing.ac.uk/courses/introduction-transparent-machine-learning                                                               |
| The Alan Turing Institute: Assessing and Mitigating Bias and Discrimination in AI             | Ethics         | Course           | https://www.turing.ac.uk/courses/assessing-and-mitigating-bias-and-discrimination-ai                                                     |
| Explainable Artificial Intelligence - Harvard University                                      | Explanability  | Course           | https://interpretable-ml-class.github.io/                                                                                                |
| The Alan Turing Institute: Operationalising Ethics in AI - Expert                             | Ethics         | Course           | https://www.turing.ac.uk/courses/operationalising-ethics-ai-expert                                                                       |
| Cybersecurity Risks of AI-Generated Code                                                      | Security       | Report           | https://cset.georgetown.edu/publication/cybersecurity-risks-of-ai-generated-code/                                                        |
| How to get into Ai policy                                                                     | Policy         | Blog             | https://posts.bcavello.com/how-to-get-into-ai-policy-part-2/#read-more                                                                   |
| What is civic participation in artificial intelligence?                                       | Policy         | Research article | https://journals.sagepub.com/doi/10.1177/23998083241296200                                                                               |
| Technology Policy Tracker                                                                     | Policy         | Tool             | https://integrityinstitute.org/legislative-tracker                                                                                       |
| LLM and Generative AI Security Solutions Landscape                                            | Security       | Whitepaper       | https://genai.owasp.org/resource/llm-and-generative-ai-security-solutions-landscape/                                                     |
| A Safe Harbor for AI Evaluation and Red Teaming                                               | Security       | Paper            | https://arxiv.org/abs/2403.04893                                                                                                         |
| Privacy Preserving GenAI at Scale: Anonymize Your Text without GPUs for a hundredth the cost. | Privacy        | Blog             | https://medium.com/thirdai-blog/privacy-preserving-genai-at-scale-anonymize-your-text-without-gpus-for-a-hundredth-the-cost-81d643a9d5fb |
| Differential Privacy: OpenDP                                                                  | Privacy        | Project          | https://opendp.org/about                                                                                                                 |
| Interpretability - Tabular SHAP explainer                                                     | Explanability  | Article          | https://learn.microsoft.com/en-us/fabric/data-science/tabular-shap-explainer                                                             |
| Create and explore the Responsible AI dashboard for a model in Azure Machine Learning         | nan            | Tutorial         | https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/?source=recommendations                  |
| METR - evaluation of Foundational models                                                      | Safety testing | Tools            | https://metr.github.io/autonomy-evals-guide/                                                                                             |
| Building LLM app                                                                              | nan            | Tutorial         | https://github.com/abhinavbom/ai-workshop                                                                                                |
| Far.AI - Trustworthy AI Research                                                              | nan            | Lab              | https://far.ai/                                                                                                                          |