| Resource                                                                                                                                                                                                                                  | Topic          | Category         |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------|:-----------------|
| [BlueDot Impact: AI Safety and AI Governance ](https://aisafetyfundamentals.com/)                                                                                                                                                         | Safety         | Course           |
| [The Alan Turing Institute: Introduction to Transparent Machine Learning](https://www.turing.ac.uk/courses/introduction-transparent-machine-learning)                                                                                     | Transparency   | Course           |
| [The Alan Turing Institute: Assessing and Mitigating Bias and Discrimination in AI](https://www.turing.ac.uk/courses/assessing-and-mitigating-bias-and-discrimination-ai)                                                                 | Ethics         | Course           |
| [Explainable Artificial Intelligence - Harvard University](https://interpretable-ml-class.github.io/)                                                                                                                                     | Explanability  | Course           |
| [The Alan Turing Institute: Operationalising Ethics in AI - Expert](https://www.turing.ac.uk/courses/operationalising-ethics-ai-expert)                                                                                                   | Ethics         | Course           |
| [Cybersecurity Risks of AI-Generated Code](https://cset.georgetown.edu/publication/cybersecurity-risks-of-ai-generated-code/)                                                                                                             | Security       | Report           |
| [How to get into Ai policy ](https://posts.bcavello.com/how-to-get-into-ai-policy-part-2/#read-more)                                                                                                                                      | Policy         | Blog             |
| [What is civic participation in artificial intelligence?](https://journals.sagepub.com/doi/10.1177/23998083241296200)                                                                                                                     | Policy         | Research article |
| [Technology Policy Tracker](https://integrityinstitute.org/legislative-tracker)                                                                                                                                                           | Policy         | Tool             |
| [LLM and Generative AI Security Solutions Landscape](https://genai.owasp.org/resource/llm-and-generative-ai-security-solutions-landscape/)                                                                                                | Security       | Whitepaper       |
| [A Safe Harbor for AI Evaluation and Red Teaming](https://arxiv.org/abs/2403.04893)                                                                                                                                                       | Security       | Paper            |
| [Privacy Preserving GenAI at Scale: Anonymize Your Text without GPUs for a hundredth the cost.](https://medium.com/thirdai-blog/privacy-preserving-genai-at-scale-anonymize-your-text-without-gpus-for-a-hundredth-the-cost-81d643a9d5fb) | Privacy        | Blog             |
| [Differential Privacy: OpenDP](https://opendp.org/about)                                                                                                                                                                                  | Privacy        | Project          |
| [Interpretability - Tabular SHAP explainer](https://learn.microsoft.com/en-us/fabric/data-science/tabular-shap-explainer)                                                                                                                 | Explanability  | Article          |
| [Create and explore the Responsible AI dashboard for a model in Azure Machine Learning](https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/?source=recommendations)                          | nan            | Tutorial         |
| [METR - evaluation of Foundational models](https://metr.github.io/autonomy-evals-guide/)                                                                                                                                                  | Safety testing | Tools            |
| [Building LLM app](https://github.com/abhinavbom/ai-workshop)                                                                                                                                                                             | nan            | Tutorial         |
| [Far.AI - Trustworthy AI Research ](https://far.ai/)                                                                                                                                                                                      | nan            | Lab              |